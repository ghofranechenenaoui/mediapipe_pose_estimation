{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab3457ab-e94f-4211-b541-a4022ccc5fc2",
   "metadata": {},
   "source": [
    "# <center>  Pose Estimation with MediaPipe </center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744614e1-310a-40ef-a488-a326458910c1",
   "metadata": {},
   "source": [
    "### 0. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf772e9-dd17-4cd3-a527-7deaec81b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa4895-06ac-4ed1-83bc-13f3b45bb382",
   "metadata": {},
   "source": [
    "### 1. Joint Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1472db4-3ec2-404d-a022-e27a49fe74df",
   "metadata": {},
   "source": [
    "<img src=\"https://google.github.io/mediapipe/images/mobile/pose_tracking_full_body_landmarks.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9cd7bb3-6d1a-4818-9bb5-058d47be5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ddb6b4-ce02-4ef9-b778-5d5b6aa22aeb",
   "metadata": {},
   "source": [
    "### 1. Angle calculation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49576d58-26cf-4ca7-ba9a-57d3c2ff9198",
   "metadata": {},
   "source": [
    "##### 1.a )  AngLe with 3 Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4549853-db48-4f60-a85c-df99912e2e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(F,M,E):\n",
    "    First = np.array(F) \n",
    "    Midle = np.array(M) \n",
    "    End = np.array(E) \n",
    "    \n",
    "    v1 = [First[0] - Midle[0], First[1] - Midle[1],First[2] - Midle[2]]\n",
    "\n",
    "    v2 = [End[0] - Midle[0], End[1] - Midle[1],End[2] - Midle[2]]\n",
    "\n",
    "    lenght1  = math.sqrt(v1[0] * v1[0] + v1[1] * v1[1] + v1[2] * v1[2])\n",
    "\n",
    "    lenght2  = math.sqrt(v2[0] * v2[0] + v2[1] * v2[1] + v2[2] * v2[2])\n",
    "    \n",
    "    radian = math.acos(np.dot(v1,v2)/(lenght1 * lenght2)) # Radian\n",
    "    angle = radian * (180/np.pi) #degree\n",
    "    \n",
    "    return round (angle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b54dd305-f35a-408c-bf8f-8af0e8f11cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle2(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f076cc3-3b3f-471f-8019-feb4f7787461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Elbow_Left_angle = calculate_angle(shoulder_Left, elbow_Left, wrist_Left)\n",
    "Elbow_Left_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943de54-0f62-4818-81ce-740daac59f8c",
   "metadata": {},
   "source": [
    "##### 1.b )  AngLe with 2 Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6dd26-fd19-4bec-ad2c-e9bd9e35527a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Real time Pose Estimation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed813df7-a0ed-4710-b8ac-360f21d77949",
   "metadata": {},
   "source": [
    "#### 2.A The angles in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae40381-b104-4bc2-876d-03243a0c0ebc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.B The angles in real time (+ or -)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20a736fe-9b80-43e6-a67b-b02b42c4388b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(776, 408)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(np.multiply(elbow, [640, 480]).astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83ebe28d-3117-4b12-b7c5-dc857f8b9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z]\n",
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].z]\n",
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "972acc18-abb4-4006-9006-dd823ac98961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9030404090881348, 0.26676493883132935, -1.3897978067398071]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoulder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c08dc8e4-9923-4389-905d-5879bda94753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_angle(shoulder, elbow, wrist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ffb35a07-13da-4148-9903-04702135b2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 1.213816523551941\n",
       "y: 0.8516172170639038\n",
       "z: -1.2644582986831665\n",
       "visibility: 0.5706676244735718"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f709769-8e8b-47da-87e4-b16366e670e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate angle\n",
    "            angle = calculate_angle2(shoulder, elbow, wrist)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(angle), \n",
    "                           tuple(np.multiply(elbow, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66f38e-dad7-442d-b33e-92dc8ebd0441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ceefe-6b0f-41a9-9c56-edb5edf6dd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31270b49-51f9-4f78-adc2-4682c747e152",
   "metadata": {},
   "source": [
    "### 2.C Walks in real time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143170f-01e1-48ec-9b5e-3bb5232aad82",
   "metadata": {},
   "source": [
    "* **If both legs are visible;**\n",
    "* **If one of the legs is placed in front of the other;**\n",
    "* **If the distance between the right ankle and the right hip is less than the distance between the left ankle and the left hip.** (Or the Distance between the Ankle Left and Hip Left <  Distance between the Ankle Right  and Hip right) ;\n",
    "* **One knee joint is in the neutral position and the other is in the flexion phase.** (one leg 180° the other is less)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcb296b-a9f1-4f80-9a30-54eb769472f7",
   "metadata": {},
   "source": [
    "#### 2.C.1 Try fisrt Condition with Legs angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "977c976e-76bf-420b-be96-6558d69dc3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count list of Steps \n",
    "def stepsCount (walksList):\n",
    "    counter = 0 \n",
    "    for i in range (len(walksList)):\n",
    "        if ((walksList[i] == 'True') and (i == len(walksList)-1)):\n",
    "            print (walksList[i])\n",
    "            counter += 1 \n",
    "            break ;          \n",
    "        if ((walksList [i] == 'True' )  and (walksList [i+1] == 'False' )):\n",
    "            print(walksList[i])\n",
    "            counter = counter +1 \n",
    "    return counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ebfe17-496f-4b45-811a-a83820f3dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #To use webcam\n",
    "\n",
    "# Steps counter variables\n",
    "counter = 0 \n",
    "steps = []\n",
    "\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "        #print(results)\n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates Right Knee\n",
    "            hip_Right =  [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            knee_Right = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            ankle_Right =[landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            \n",
    "             # Get coordinates Left Knee\n",
    "            hip_Left =  [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            knee_Left = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            ankle_Left =[landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            \n",
    "            \n",
    "            #Angle Calculation\n",
    "\n",
    "            # Calculate Right knee\n",
    "            Knee_Right_angle = calculate_angle(hip_Right, knee_Right, ankle_Right)\n",
    "        \n",
    "            #Calculate Left knee\n",
    "            Knee_Left_angle = calculate_angle(hip_Left, knee_Left, ankle_Left)\n",
    "\n",
    "    \n",
    "            # Steps counter \n",
    "            if ((Knee_Right_angle >= 170) and  (Knee_Left_angle<170)) :\n",
    "                steps.append(True)\n",
    "                counter +=1 \n",
    "            elif ((Knee_Left_angle >= 170) and  (Knee_Right_angle<170)):\n",
    "                steps.append(True)\n",
    "                counter =+1 \n",
    "            else :\n",
    "                steps.append(False)\n",
    "         \n",
    "            # Visualize Angles ******************************************************\n",
    "            # Visualize  180°-Knee left angle\n",
    "            cv2.putText(image, str(180-Knee_Left_angle), \n",
    "                        tuple (np.multiply(knee_Left, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (245,117,66), 2, cv2.LINE_AA)\n",
    "            \n",
    "            \n",
    "            # Visualize  180°-Knee Right angle\n",
    "            cv2.putText(image, str(180-Knee_Right_angle), \n",
    "                        tuple (np.multiply(knee_Right, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (245,117,66), 2, cv2.LINE_AA)               \n",
    "        except:\n",
    "            pass\n",
    "   \n",
    "        # Steps visualisation\n",
    "        cv2.putText(image, 'Steps', (15,12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(image, str(stepsCount(steps)), \n",
    "                    (10,60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Pose Estimation', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('k'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f09cda-2c2c-4cb2-a596-950b55708f51",
   "metadata": {},
   "source": [
    "#### 2.B.2 Try Second Condition with Legs y axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85849b37-3992-49e5-a9a5-bbb9eac7fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #To use webcam\n",
    "\n",
    "# Steps counter variables\n",
    "counter = 0 \n",
    "steps = []\n",
    "boolStep = ''\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "        #print(results)\n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates Right Knee\n",
    "            hip_Right =  [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].z]\n",
    "            knee_Right = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].z]\n",
    "            ankle_Right =[landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].z]\n",
    "            \n",
    "             # Get coordinates Left Knee\n",
    "            hip_Left =  [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].z]\n",
    "            knee_Left = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].z]\n",
    "            ankle_Left =[landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].z]\n",
    "            \n",
    "            \n",
    "            # Angle Calculation\n",
    "            # Calculate Right knee\n",
    "            Knee_Right_angle = calculate_angle(hip_Right, knee_Right, ankle_Right)\n",
    "        \n",
    "            #Calculate Left knee\n",
    "            Knee_Left_angle = calculate_angle(hip_Left, knee_Left, ankle_Left)\n",
    "\n",
    "    \n",
    "            # Steps counter \n",
    "            if ((Knee_Right_angle >= 170) and  (Knee_Left_angle<170) and (ankle_Right[1] > ankle_Left[1]) ) :\n",
    "                steps.append(True)\n",
    "                boolStep = 'True'\n",
    "                counter +=1 \n",
    "            elif ((Knee_Left_angle >= 170) and  (Knee_Right_angle<170) and  (ankle_Right[1] < ankle_Left[1])):\n",
    "                steps.append(True)\n",
    "                boolStep = 'True'\n",
    "                counter =+1 \n",
    "            else :\n",
    "                steps.append(False)\n",
    "                boolStep = 'True'\n",
    "\n",
    "         \n",
    "            # Visualize Angles ******************************************************\n",
    "            # Visualize  180°-Knee left angle\n",
    "            cv2.putText(image, str(180-Knee_Left_angle), \n",
    "                        tuple (np.multiply(knee_Left, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (245,117,66), 2, cv2.LINE_AA)\n",
    "            \n",
    "            \n",
    "            # Visualize  180°-Knee Right angle\n",
    "            cv2.putText(image, str(180-Knee_Right_angle), \n",
    "                        tuple (np.multiply(knee_Right, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (245,117,66), 2, cv2.LINE_AA)               \n",
    "        except:\n",
    "            pass\n",
    "   \n",
    "        # Steps visualisation\n",
    "        cv2.putText(image, 'Steps', (15,12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(image, str(boolStep), \n",
    "                    (10,60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Pose Estimation', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('k'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8330c282-7ec4-4e4b-bde8-8cbf6cd9ca81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
